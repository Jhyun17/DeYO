# Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors
![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)  

This is the official implementation of [Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors ðŸ”—](https://openreview.net/forum?id=9w3iw8wDuE) 
by Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang and Sungroh Yoon (**ICLR 2024 Spotlight, Top-5% of the submissions**).  
This implementation is based on [SAR implementation ðŸ”—](https://github.com/mr-eggplant/SAR).

## Environments  

You should modify [username] and [env_name] in environment.yaml, then  
> $ conda env create --file environment.yaml  

## Baselines  
[TENT ðŸ”—](https://arxiv.org/abs/2006.10726) (ICLR 2021)  
[EATA ðŸ”—](https://arxiv.org/abs/2204.02610) (ICML 2022)  
[SAR ðŸ”—](https://arxiv.org/abs/2302.12400) (ICLR 2023)  

## Dataset
You can download ImageNet-C from a link [ImageNet-C ðŸ”—](https://zenodo.org/record/2235448).  

After downloading the dataset, move to the root directory ([data_root]) of datasets.  

If you run on [ColoredMNIST ðŸ”—](https://arxiv.org/abs/1907.02893) or [Waterbirds ðŸ”—](https://arxiv.org/abs/1911.08731), run  
> $ python pretrain_[dataset_name].py --root_dir [data_root] --dset [dataset_name]

Then datasets are automatically downloaded in your [data_root] directory.  
(ColoredMNIST from [torchvision ðŸ”—](https://pytorch.org/vision/stable/index.html) and ./dataset/ColoredMNIST_dataset.py, Waterbirds from [wilds ðŸ”—](https://pypi.org/project/wilds/) package)

Your [data_root] will be as follows:
```bash
data_root
â”œâ”€â”€ ImageNet-C
â”‚   â”œâ”€â”€ brightness
â”‚   â”œâ”€â”€ contrast
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ColoredMNIST
â”‚   â”œâ”€â”€ ColoredMNIST_model.pickle
â”‚   â”œâ”€â”€ MNIST
â”‚   â”œâ”€â”€ train1.pt
â”‚   â”œâ”€â”€ train2.pt
â”‚   â””â”€â”€ test.pt
â”œâ”€â”€ Waterbirds
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â”œâ”€â”€ waterbirds_dataset.h5py
â”‚   â”œâ”€â”€ waterbirds_pretrained_model.pickle
â”‚   â”œâ”€â”€ 001. Black_footed_Albatross
â”‚   â”œâ”€â”€ 002. Laysan_Albatross
â””â”€â”€ â””â”€â”€ ...
```
If you don't want to pre-train, you can just copy and paste the [dataset_name]_model.pickle from './pretrained/' directory.

## Experiment

You can run most of the experiments in our paper by  
> $ chmod +x exp_deyo.sh  
> $ ./exp_deyo.sh  

If you want to run on the ImageNet-R or VISDA-2021, you should use main_da.py

You should modify ROOT variable as [data_root] in exp_deyo.sh.  

## Citation
If our DeYO method or biased test-time adaptation settings are helpful in your research, please consider citing our paper:
```
@inproceedings{
    lee2024entropy,
    title={Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors},
    author={Jonghyun Lee and Dahuin Jung and Saehyung Lee and Junsung Park and Juhyeon Shin and Uiwon Hwang and Sungroh Yoon},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=9w3iw8wDuE}
}
```

## Acknowledgment
The code is inspired by the [Tent ðŸ”—](https://github.com/DequanWang/tent), [EATA ðŸ”—](https://github.com/mr-eggplant/EATA), and [SAR ðŸ”—](https://github.com/mr-eggplant/SAR).
